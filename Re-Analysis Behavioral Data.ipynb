{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Analysis of behavioral data and comparison with Kolossa model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Jan 15 20:32:41 2014\n",
    "\n",
    "@author: moritz\n",
    "\"\"\"\n",
    "\n",
    "#get the data as np_array of the form chan*time*epochs\n",
    "from __future__ import division\n",
    "#re-test for gammas/pnulls\n",
    "%matplotlib inline\n",
    "from helper_functions import *\n",
    "\n",
    "#import re\n",
    "import os\n",
    "import pystan\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#this is the model\n",
    "\n",
    "hierarchic_model = \"\"\"\n",
    "data {\n",
    "int<lower=0> npb;\n",
    "int<lower=0> cases;\n",
    "int<lower=0> N[npb,cases];\n",
    "int<lower=0> y[npb,cases];\n",
    "real X[cases];\n",
    "}\n",
    "parameters {\n",
    "real<lower=0> mu_gam;\n",
    "real<lower=0> tau_gam;\n",
    "real mu_pz;\n",
    "real<lower=0> tau_pz;\n",
    "real<lower=0> gam[npb];\n",
    "real pzero[npb];\n",
    "}\n",
    "model {\n",
    "\n",
    "mu_gam ~ normal(1,1) T[0,];\n",
    "mu_pz ~ normal(0,10);\n",
    "gam ~ normal(mu_gam,tau_gam);\n",
    "pzero ~ normal(mu_pz,tau_pz);\n",
    "\n",
    "\n",
    "for (i in 1:cases)\n",
    "{\n",
    "for (j in 1:npb)\n",
    "y[j,i] ~ binomial_logit(N[j,i],X[i]*gam[j] + (1-gam[j])*pzero[j]);\n",
    "}\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "hierarchic_model_kolossa = \"\"\"\n",
    "data {\n",
    "int<lower=0> npb;\n",
    "int<lower=0> cases;\n",
    "int<lower=0> N[npb,cases];\n",
    "int<lower=0> y[npb,cases];\n",
    "real X[cases];\n",
    "}\n",
    "parameters {\n",
    "real<lower=0> mu_gam;\n",
    "real<lower=0> tau_gam;\n",
    "real<lower=0> gam[npb];\n",
    "}\n",
    "model {\n",
    "\n",
    "mu_gam ~ normal(1,1) T[0,];\n",
    "gam ~ normal(mu_gam,tau_gam);\n",
    "\n",
    "\n",
    "for (i in 1:cases)\n",
    "{\n",
    "for (j in 1:npb)\n",
    "y[j,i] ~ binomial_logit(N[j,i],X[i]*gam[j]);\n",
    "}\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "hierarchic_model_kolossa2 = \"\"\"\n",
    "data {\n",
    "int<lower=0> npb;\n",
    "int<lower=0> cases;\n",
    "int<lower=0> N[npb,cases];\n",
    "int<lower=0> y[npb,cases];\n",
    "real X[cases];\n",
    "}\n",
    "parameters {\n",
    "real<lower=0> mu_gam;\n",
    "real<lower=0> tau_gam;\n",
    "real<lower=0> gam[npb];\n",
    "}\n",
    "model {\n",
    "\n",
    "mu_gam ~ normal(1,1) T[0,];\n",
    "gam ~ normal(mu_gam,tau_gam);\n",
    "\n",
    "\n",
    "for (i in 1:cases)\n",
    "{\n",
    "for (j in 1:npb)\n",
    "y[j,i] ~ binomial_logit(N[j,i],X[i]*gam[j]);\n",
    "}\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "k_model = \"\"\"\n",
    "data {\n",
    "int<lower=0> N;\n",
    "real x[N,4];\n",
    "int<lower=0,upper=1> y[N];\n",
    "}\n",
    "parameters {\n",
    "real<lower=0> gam;\n",
    "}\n",
    "model {\n",
    "\n",
    "gam ~ normal(1,1) T[0,];\n",
    "\n",
    "for (n in 1:N)\n",
    "y[n] ~ bernoulli(inv_logit(gam * x[n,4]+x[n,3]*gam^2+x[n,2]*gam^3+x[n,1]*gam^4));\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "k_model2 = \"\"\"\n",
    "data {\n",
    "int<lower=0> N;\n",
    "real x[N,4];\n",
    "int<lower=0,upper=1> y[N];\n",
    "}\n",
    "parameters {\n",
    "real<lower=0> gam;\n",
    "real pz;\n",
    "}\n",
    "model {\n",
    "\n",
    "gam ~ normal(1,1) T[0,];\n",
    "pz ~ normal(0,1.45);\n",
    "for (n in 1:N)\n",
    "y[n] ~ bernoulli(inv_logit(gam * x[n,4]+x[n,3]*gam^2+x[n,2]*gam^3+x[n,1]*gam^4+((1-gam)*pz)+((1-gam)*pz)^2+((1-gam)*pz)^3+((1-gam)*pz)^4));\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list the files, assuming a folder structure of cwd/Data/...\n",
    "files = os.listdir(\"Data/newdata/\")\n",
    "\n",
    "#now get all the data for exp80\n",
    "pattern = \"80exp\"\n",
    "\n",
    "exp80_y = pd.DataFrame({0:14*[0]})\n",
    "exp80_n = pd.DataFrame({0:14*[0]})\n",
    "\n",
    "for fn in files:\n",
    "    if pattern in fn:\n",
    "        tmp = pd.read_table(\"Data/newdata/\"+fn,sep=\" \",header=None)\n",
    "        exp80_y[int(fn[5:7])] = tmp[0]\n",
    "        exp80_n[int(fn[5:7])] = tmp[1]\n",
    "       \n",
    "#now sort them\n",
    "exp80_n.sort_index(axis=1,inplace=True)\n",
    "exp80_y.sort_index(axis=1,inplace=True)\n",
    "\n",
    "#for easier use convert to array/CHANGE THIS LATER\n",
    "\n",
    "exp80_n = exp80_n.as_matrix() \n",
    "exp80_y = exp80_y.as_matrix()\n",
    "\n",
    "#and also drop the first column\n",
    "\n",
    "exp80_n = exp80_n[:,1:]\n",
    "exp80_y = exp80_y[:,1:]\n",
    "\n",
    "#pop first 2 cases, so no first ball\n",
    "exp80_n = exp80_n[2:,:]\n",
    "exp80_y = exp80_y[2:,:]\n",
    "#03a or 03?\n",
    "#now you can start re-analysing the data\n",
    "#there are 16 vps\n",
    "npb = 16\n",
    "#and 14 (12 without 1st ball) different cases for the binomial distribution\n",
    "cases = 12\n",
    "\n",
    "#also, we need the actual posterior probabilities as logits\n",
    "\n",
    "\n",
    "prior = 0.2\n",
    "likelihood = 0.7\n",
    "\n",
    "x = np.array([(prior*(likelihood**j)*((1-likelihood)**(i-j)))/(((1-prior)*((likelihood**(i-j))*((1-likelihood)**j)))+(prior*(likelihood**j)*((1-likelihood)**(i-j)))) for i in xrange(1,5) for j in xrange(i+1)])\n",
    "lo_x = np.log(x/(1-x))\n",
    "#and again drop first ball/2 cases\n",
    "lo_x = lo_x[2:]\n",
    "\n",
    "#transpose so rows are vps and columns are cases\n",
    "exp80_n = exp80_n.T\n",
    "exp80_y = exp80_y.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with 3 balls, non-unique posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "#ONLY FOR 3 BALLS AND MODEL WITH NON-UNIQUE POSTERIORS\n",
    "#create the data-structure\n",
    "data_exp80 = {\"npb\" : npb,\"cases\":cases,\"N\":exp80_n,\"y\":exp80_y,\"X\":lo_x}\n",
    "#fit now\n",
    "fit = pystan.stan(model_code=hierarchic_model_kolossa, data=data_exp80,iter=10000, chains=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with only unique posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "#MODEL WITH ONLY UNIQUE POSTERIORS \n",
    "#try to compress X, so same values are added\n",
    "#first round\n",
    "\n",
    "lo_x = around(lo_x,3)\n",
    "\n",
    "#now add n and y with the same X (with cool comprehension)\n",
    "\n",
    "exp80_n = array( [ sum(exp80_n[:,lo_x==lx],1) for lx in unique(lo_x)]).T\n",
    "exp80_y = array( [ sum(exp80_y[:,lo_x==lx],1) for lx in unique(lo_x)]).T\n",
    "\n",
    "#update cases\n",
    "cases = exp80_n.shape[1]\n",
    "\n",
    "data_exp80 = {\"npb\" : npb,\"cases\":cases,\"N\":exp80_n,\"y\":exp80_y,\"X\":unique(lo_x)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "fit = pystan.stan(model_code=hierarchic_model, data=data_exp80,\n",
    "                 iter=40000, chains=20)\n",
    "#%%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with Kolossa model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "likelihood = { 1 : 0.3, 2: 0.7 }\n",
    "prior = 0.2\n",
    "\n",
    "path = \"/home/mboos/Work/Bayesian Updating/Data/\"\n",
    "path_mat = \"/home/mboos/Work/Bayesian Updating/Data EEG/\"\n",
    "\n",
    "files = os.listdir(path)\n",
    "mat_files = os.listdir(path_mat)\n",
    "\n",
    "pattern_TS = \"80exp\"\n",
    "pattern = \"exp80\"\n",
    "\n",
    "blist_dict = dict()\n",
    "brar_dict = dict()\n",
    "\n",
    "#%%\n",
    "#strip VEOH,HEOG electrodes\n",
    "\n",
    "#100ms BEFORE stimulus presentation\n",
    "\n",
    "\n",
    "for fn in files:\n",
    "    if fn.startswith(\"TS\") and pattern_TS in fn:\n",
    "        bclass = get_bclass_list(fn,prior,likelihood)\n",
    "        brar_dict[fn[4:6]] = get_bclass(fn,prior,likelihood)[:,0]\n",
    "        blist_dict[fn[4:6]] = bclass\n",
    "\n",
    " \n",
    "for pb in sorted(blist_dict.keys()):\n",
    "    for i,e in enumerate(blist_dict[pb]):\n",
    "        blist_dict[pb][i][0] = e[0] + e[1]\n",
    "        blist_dict[pb][i].pop(1)\n",
    "        blist_dict[pb][i] = [0 for t in xrange(4-len(blist_dict[pb][i]))] + blist_dict[pb][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = np.concatenate([brar_dict[pb]-1 for pb in brar_dict.keys()])\n",
    "X = np.vstack([blist_dict[pb] for pb in brar_dict.keys()])\n",
    "X = X[y>=0,:]\n",
    "y = y[y>=0]\n",
    "y = [int(i) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mboos/anaconda/lib/python2.7/multiprocessing/queues.py:390: UserWarning: Pickling fit objects is an experimental feature!\n",
      "The relevant StanModel instance must be pickled along with this fit object.\n",
      "When unpickling the StanModel must be unpickled first.\n",
      "  return send(obj)\n",
      "/home/mboos/anaconda/lib/python2.7/multiprocessing/queues.py:390: UserWarning: Pickling fit objects is an experimental feature!\n",
      "The relevant StanModel instance must be pickled along with this fit object.\n",
      "When unpickling the StanModel must be unpickled first.\n",
      "  return send(obj)\n",
      "/home/mboos/anaconda/lib/python2.7/multiprocessing/queues.py:390: UserWarning: Pickling fit objects is an experimental feature!\n",
      "The relevant StanModel instance must be pickled along with this fit object.\n",
      "When unpickling the StanModel must be unpickled first.\n",
      "  return send(obj)\n",
      "/home/mboos/anaconda/lib/python2.7/multiprocessing/queues.py:390: UserWarning: Pickling fit objects is an experimental feature!\n",
      "The relevant StanModel instance must be pickled along with this fit object.\n",
      "When unpickling the StanModel must be unpickled first.\n",
      "  return send(obj)\n"
     ]
    }
   ],
   "source": [
    "k_data = {'N' : X.shape[0],'x':X,'y':y}\n",
    "fit = pystan.stan(model_code=k_model, data=k_data,iter=5000, chains=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mboos/anaconda/lib/python2.7/multiprocessing/queues.py:390: UserWarning: Pickling fit objects is an experimental feature!\n",
      "The relevant StanModel instance must be pickled along with this fit object.\n",
      "When unpickling the StanModel must be unpickled first.\n",
      "  return send(obj)\n",
      "/home/mboos/anaconda/lib/python2.7/multiprocessing/queues.py:390: UserWarning: Pickling fit objects is an experimental feature!\n",
      "The relevant StanModel instance must be pickled along with this fit object.\n",
      "When unpickling the StanModel must be unpickled first.\n",
      "  return send(obj)\n",
      "/home/mboos/anaconda/lib/python2.7/multiprocessing/queues.py:390: UserWarning: Pickling fit objects is an experimental feature!\n",
      "The relevant StanModel instance must be pickled along with this fit object.\n",
      "When unpickling the StanModel must be unpickled first.\n",
      "  return send(obj)\n",
      "/home/mboos/anaconda/lib/python2.7/multiprocessing/queues.py:390: UserWarning: Pickling fit objects is an experimental feature!\n",
      "The relevant StanModel instance must be pickled along with this fit object.\n",
      "When unpickling the StanModel must be unpickled first.\n",
      "  return send(obj)\n"
     ]
    }
   ],
   "source": [
    "k_data = {'N' : X.shape[0],'x':X,'y':y}\n",
    "fit = pystan.stan(model_code=k_model2, data=k_data,iter=10000, chains=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inference for Stan model: anon_model_a57465d4dff3e6b6213a670a858663ea.\n",
       "10 chains, each with iter=10000; warmup=5000; thin=1; \n",
       "post-warmup draws per chain=5000, total post-warmup draws=50000.\n",
       "\n",
       "       mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
       "gam    0.88  1.6e-4   0.01   0.86   0.88   0.88   0.89   0.91 5700.0    1.0\n",
       "pz     3.98  7.2e-3   0.54   3.03   3.59   3.95   4.32   5.16 5635.0    1.0\n",
       "lp__  -1257    0.01   1.01  -1260  -1258  -1257  -1257  -1256 7192.0    1.0\n",
       "\n",
       "Samples were drawn using NUTS(diag_e) at Wed Aug  5 18:32:44 2015.\n",
       "For each parameter, n_eff is a crude measure of effective sample size,\n",
       "and Rhat is the potential scale reduction factor on split chains (at \n",
       "convergence, Rhat=1)."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
